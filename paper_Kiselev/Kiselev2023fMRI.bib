@article{Berezutskaya2022,
  doi = {10.1038/s41597-022-01173-0},
  url = {https://doi.org/10.1038/s41597-022-01173-0},
  year = {2022},
  month = mar,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {9},
  number = {1},
  author = {Julia Berezutskaya and Mariska J. Vansteensel and Erik J. Aarnoutse and Zachary V. Freudenburg and Giovanni Piantoni and Mariana P. Branco and Nick F. Ramsey},
  title = {Open multimodal {iEEG}-{fMRI} dataset from naturalistic stimulation with a short audiovisual film},
  journal = {Scientific Data}
}

@article{menon1999spatial,
  title={Spatial and temporal limits in cognitive neuroimaging with fMRI},
  author={Menon, Ravi S and Kim, Seong-Gi},
  journal={Trends in cognitive sciences},
  volume={3},
  number={6},
  pages={207--216},
  year={1999},
  publisher={Elsevier}
}

@article{logothetis2008we,
  title={What we can do and what we cannot do with fMRI},
  author={Logothetis, Nikos K},
  journal={Nature},
  volume={453},
  number={7197},
  pages={869--878},
  year={2008},
  publisher={Nature Publishing Group UK London}
}

@misc{1804.10167,
Author = {Maxim Sharaev and Alexander Andreev and Alexey Artemov and Alexander Bernstein and Evgeny Burnaev and Ekaterina Kondratyeva and Svetlana Sushchinskaya and Renat Akzhigitov},
Title = {fMRI: preprocessing, classification and pattern recognition},
Year = {2018},
Eprint = {arXiv:1804.10167},
}

@article{boersma2018praat,
  title={Praat: doing phonetics by computer [Computer program]. Version 6.0. 37},
  author={Boersma, Paul and Weenink, David},
  journal={Retrieved February},
  volume={3},
  pages={2018},
  year={2018}
}

@article{Berezutskaya2020,
  doi = {10.1038/s41598-020-68853-y},
  url = {https://doi.org/10.1038/s41598-020-68853-y},
  year = {2020},
  month = jul,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {10},
  number = {1},
  author = {Julia Berezutskaya and Zachary V. Freudenburg and Luca Ambrogioni and Umut G\"{u}{\c{c}}l\"{u} and Marcel A. J. van Gerven and Nick F. Ramsey},
  title = {Cortical network responses map onto data-driven features that capture visual semantics of movie fragments},
  journal = {Scientific Reports}
}

@article{Glover2011,
  doi = {10.1016/j.nec.2010.11.001},
  url = {https://doi.org/10.1016/j.nec.2010.11.001},
  year = {2011},
  month = apr,
  publisher = {Elsevier {BV}},
  volume = {22},
  number = {2},
  pages = {133--139},
  author = {Gary H. Glover},
  title = {Overview of Functional Magnetic Resonance Imaging},
  journal = {Neurosurgery Clinics of North America}
}

@article{Logothetis2003,
  doi = {10.1523/jneurosci.23-10-03963.2003},
  url = {https://doi.org/10.1523/jneurosci.23-10-03963.2003},
  year = {2003},
  month = may,
  publisher = {Society for Neuroscience},
  volume = {23},
  number = {10},
  pages = {3963--3971},
  author = {Nikos K. Logothetis},
  title = {The Underpinnings of the {BOLD} Functional Magnetic Resonance Imaging Signal},
  journal = {The Journal of Neuroscience}
}

@misc{https://doi.org/10.48550/arxiv.1706.03762,
  doi = {10.48550/ARXIV.1706.03762},
  url = {https://arxiv.org/abs/1706.03762},
  author = {Vaswani,  Ashish and Shazeer,  Noam and Parmar,  Niki and Uszkoreit,  Jakob and Jones,  Llion and Gomez,  Aidan N. and Kaiser,  Lukasz and Polosukhin,  Illia},
  keywords = {Computation and Language (cs.CL),  Machine Learning (cs.LG),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Attention Is All You Need},
  publisher = {arXiv},
  year = {2017},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}

@misc{https://doi.org/10.48550/arxiv.2201.04288,
  doi = {10.48550/ARXIV.2201.04288},
  url = {https://arxiv.org/abs/2201.04288},
  author = {Yan,  Shen and Xiong,  Xuehan and Arnab,  Anurag and Lu,  Zhichao and Zhang,  Mi and Sun,  Chen and Schmid,  Cordelia},
  keywords = {Computer Vision and Pattern Recognition (cs.CV),  Machine Learning (cs.LG),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Multiview Transformers for Video Recognition},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution 4.0 International}
}